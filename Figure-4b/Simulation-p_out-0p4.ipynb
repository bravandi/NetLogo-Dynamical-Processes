{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a03d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib as mpl\n",
    "import datetime\n",
    "import math\n",
    "from scipy.stats import norm, kurtosis, mode\n",
    "cmap = plt.get_cmap('tab10')\n",
    "from scipy.stats import describe\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f36aad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_simulation(p_out,G_input, N_walkers,initial_node_with_walkers,run_time):\n",
    "    end_time_list = []\n",
    "    r_square_re = []\n",
    "    for iter_num in range(run_time):\n",
    "        #G = G_ba.copy()\n",
    "        G = G_input.copy()\n",
    "        N_nodes = list(G.nodes())\n",
    "\n",
    "\n",
    "        ### Asign the walker\n",
    "        nx.set_node_attributes(G, [0],'history')\n",
    "        initial_walkers = random.sample(N_nodes,initial_node_with_walkers)\n",
    "        for i in initial_walkers:\n",
    "            G.nodes[i]['history'] = [N_walkers / initial_node_with_walkers]\n",
    "        \n",
    "        degree_of_initial = [G.degree(k) for k in initial_walkers]\n",
    "\n",
    "        # the x (expected final distribution of walkers) of the linear regression\n",
    "        walker_per_degree = N_walkers/sum([j for (i,j) in G.degree])\n",
    "        degree_list = np.array([j*walker_per_degree for (i,j) in G.degree])\n",
    "        degree_list = degree_list.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        # Run the simulation model until the R-square over 0.99\n",
    "        linear_score = [0]\n",
    "        end_time = 0\n",
    "        while linear_score[-1] <0.99:\n",
    "            end_time += 1\n",
    "            for nodes in G.nodes:\n",
    "                tem_out_list = [n for n in G.neighbors(nodes)]\n",
    "                tem_in_node = 0\n",
    "                for neigh_node in tem_out_list:\n",
    "                    tem_in_node += G.nodes[neigh_node]['history'][end_time-1] * p_out / len([n for n in G.neighbors(neigh_node)])\n",
    "                G.nodes[nodes]['history'] = G.nodes[nodes]['history']+[tem_in_node + G.nodes[nodes]['history'][end_time-1] * (1-p_out)]\n",
    "            ## Run the linear regression\n",
    "            check_list = []\n",
    "            for nodes in G.nodes:\n",
    "                check_list.append(G.nodes[nodes]['history'][-1])\n",
    "            reg = LinearRegression().fit(degree_list, check_list)\n",
    "            linear_score.append(round(reg.score(degree_list, check_list),4))\n",
    "        # record the end time of each simulation    \n",
    "        end_time_list.append(end_time)\n",
    "        \n",
    "    return end_time_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e9fab3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [09:39<00:00, 57.96s/it]\n"
     ]
    }
   ],
   "source": [
    "p_out = 0.4\n",
    "end_time_all_ER = []\n",
    "end_time_all_BA = []\n",
    "N_walkers = 10000\n",
    "initial_node_with_walkers = 4\n",
    "run_time = 100\n",
    "\n",
    "for _ in tqdm(range(90,100)): ## 100 graph instances\n",
    "    \n",
    "    G_BA_total = nx.read_gpickle('data/4b-BA-instance-' + str(_) + '.pickle')\n",
    "    G_ER_total = nx.read_gpickle('data/4b-ER-instance-' + str(_) + '.pickle')\n",
    "\n",
    "    Gcc = sorted(nx.connected_components(G_BA_total), key=len, reverse=True)\n",
    "    G_BA = G_BA_total.subgraph(Gcc[0])\n",
    "\n",
    "    Gcc = sorted(nx.connected_components(G_ER_total), key=len, reverse=True)\n",
    "    G_ER = G_ER_total.subgraph(Gcc[0])\n",
    "\n",
    "    end_time_list_ER = one_simulation(p_out,G_ER, N_walkers, initial_node_with_walkers, run_time)\n",
    "    end_time_list_BA = one_simulation(p_out,G_BA, N_walkers, initial_node_with_walkers, run_time)\n",
    "    \n",
    "    end_time_all_ER.append(end_time_list_ER)\n",
    "    end_time_all_BA.append(end_time_list_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c72ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('data/4b-end_time_all_ER_0_89_simulations_p_out' + str(p_out) + '.npy', np.array(end_time_all_ER))\n",
    "#np.save('data/4b-end_time_all_BA_0_89_simulations_p_out_' + str(p_out) + '.npy', np.array(end_time_all_BA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9dcf7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/4b-end_time_all_ER_90_100_simulations_p_out' + str(p_out) + '.npy', np.array(end_time_all_ER))\n",
    "np.save('data/4b-end_time_all_BA_90_100_simulations_p_out_' + str(p_out) + '.npy', np.array(end_time_all_BA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa57138-4f4b-4a1b-8c2b-0481360161fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
